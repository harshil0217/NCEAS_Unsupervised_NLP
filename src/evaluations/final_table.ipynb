{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "\n",
    "# Set the target folder name you want to reach\n",
    "target_folder = \"phate-for-text\"\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Loop to move up the directory tree until we reach the target folder\n",
    "while os.path.basename(current_dir) != target_folder:\n",
    "    parent_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "    if parent_dir == current_dir:\n",
    "        # If we reach the root directory and haven't found the target, exit\n",
    "        raise FileNotFoundError(f\"{target_folder} not found in the directory tree.\")\n",
    "    current_dir = parent_dir\n",
    "\n",
    "# Change the working directory to the folder where \"phate-for-text\" is found\n",
    "os.chdir(current_dir)\n",
    "\n",
    "# Add the \"phate-for-text\" directory to sys.path\n",
    "sys.path.insert(0, current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example dictionary: replace this with your actual dictionary\n",
    "data_sources = {\n",
    "    \"Amazon\":\"text-embedding-3-large_results/other_amz_results.csv\",\n",
    "    \"Web of science\":\"text-embedding-3-large_results/other_WOS_results.csv\",\n",
    "    \"DBpedia\":\"text-embedding-3-large_results/other_dbpedia_results_test.csv\",\n",
    "    \"Ecosystems (d)\":\"text-embedding-3-large_results/processed_results_Energy, Ecosystems, and Humans_t1.0_maxsub3_depth5_random.csv\",\n",
    "    \"Fisheries (d)\":\"text-embedding-3-large_results/processed_results_Offshore energy impacts on fisheries_t1.0_maxsub3_depth5_random.csv\",\n",
    "    \"Ecosystems (s)\":\"text-embedding-3-large_results/processed_results_Energy, Ecosystems, and Humans_t1.0_maxsub5_depth3_random.csv\",\n",
    "    \"Fisheries (s)\":\"text-embedding-3-large_results/processed_results_Offshore energy impacts on fisheries_t1.0_maxsub5_depth3_random.csv\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "maximum = False\n",
    "\n",
    "for source, filepath in data_sources.items():\n",
    "    df = pd.read_csv(filepath)\n",
    "    df=df.fillna(\"None\")\n",
    "\n",
    "\n",
    "    if 'reduction_params' in df.columns:\n",
    "        df['Params']= df['reduction_params']+df['cluster_params']\n",
    "    elif 'Params' not in df.columns:\n",
    "        df['Params'] = ['None']*len(df)\n",
    "    \n",
    "    # Group by the three columns and take the median of the score columns\n",
    "\n",
    "    if maximum:\n",
    "        grouped_mean = df.groupby(['reduction_method', 'cluster_method', 'level','Params'])[['ARI']].mean().reset_index()\n",
    "    \n",
    "        # Then group by the two columns and take the mean\n",
    "        grouped_max = grouped_mean.groupby(['reduction_method', 'cluster_method'])[['ARI']].max().reset_index()\n",
    "        grouped_max['source'] = source\n",
    "    \n",
    "    # Append to list\n",
    "        results.append(grouped_max)\n",
    "    else:\n",
    "        grouped_median = df.groupby(['reduction_method', 'cluster_method', 'level'])[['ARI']].median().reset_index()\n",
    "        \n",
    "        # Then group by the two columns and take the meanmi\n",
    "        grouped_mean = grouped_median.groupby(['reduction_method', 'cluster_method'])[['ARI']].mean().reset_index()\n",
    "        \n",
    "        # Add the source column\n",
    "        grouped_mean['source'] = source\n",
    "    \n",
    "    # Append to list\n",
    "        results.append(grouped_mean)\n",
    "\n",
    "# Concatenate all results\n",
    "final_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# Optional: display or save\n",
    "final_df=final_df.replace({\"DC\":\"Diffusion condensation\"})\n",
    "final_df=final_df.replace({\"Diffusion Condensation\":\"Diffusion condensation\"})\n",
    "final_df = final_df[final_df['reduction_method']!=\"BASE-PHATE\"]\n",
    "final_df = final_df[final_df['reduction_method']!=\"None\"]\n",
    "final_df = final_df[final_df['reduction_method']!=\"tSNE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reduction_method</th>\n",
       "      <th>cluster_method</th>\n",
       "      <th>ARI</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [reduction_method, cluster_method, ARI, source]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "final_df[final_df['cluster_method']==\"Diffusion Condensation\"].sort_values(by='ARI',ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalIndex(['Web of science', 'DBpedia', 'Amazon', 'Fisheries (d)',\n",
      "                  'Fisheries (s)', 'Ecosystems (d)', 'Ecosystems (s)'],\n",
      "                 categories=['Web of science', 'DBpedia', 'Amazon', 'Fisheries (d)', 'Fisheries (s)', 'Ecosystems (d)', 'Ecosystems (s)'], ordered=True, dtype='category', name='source')\n",
      "LaTeX code has been saved to 'pivot_table.tex'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you already have your DataFrame\n",
    "# Replace this with your actual DataFrame\n",
    "df = final_df\n",
    "\n",
    "# Create a multi-index DataFrame for the pivot table\n",
    "reduction_order = ['PHATE', 'PCA', 'UMAP', 'T-SNE']\n",
    "cluster_order = ['Diffusion condensation', 'Agglomerative','HDBSCAN']\n",
    "source_order = ['Web of science', 'DBpedia', 'Amazon','Fisheries (d)', 'Fisheries (s)','Ecosystems (d)','Ecosystems (s)']\n",
    "\n",
    "# Set categorical types with specified order\n",
    "df['reduction_method'] = pd.Categorical(df['reduction_method'], categories=reduction_order, ordered=True)\n",
    "df['cluster_method'] = pd.Categorical(df['cluster_method'], categories=cluster_order, ordered=True)\n",
    "df['source'] = pd.Categorical(df['source'], categories=source_order, ordered=True)\n",
    "\n",
    "# Now pivot\n",
    "pivot = df.pivot_table(\n",
    "    index=['reduction_method', 'cluster_method'],\n",
    "    columns='source',\n",
    "    values='ARI'  # No need for ['ARI'] unless you have multiple values\n",
    ")\n",
    "\n",
    "# Optional: sort the index to reflect the custom order\n",
    "pivot = pivot.sort_index()\n",
    "def pivot_to_latex(pivot_table, file_name=\"pivot_table.tex\"):\n",
    "    # Determine max and second max values per column\n",
    "    max_values = pivot_table.max(axis=0)\n",
    "    second_max_values = pivot_table.apply(lambda col: col[col != col.max()].max())\n",
    "\n",
    "    with open(file_name, \"w\") as f:\n",
    "        f.write(\"\\\\begin{table}\\n\")\n",
    "        f.write(\"\\\\begin{document}\\n\")\n",
    "        f.write(\"[ht]\\n\")\n",
    "        f.write(\"\\\\centering\\n\")\n",
    "        f.write(\"\\\\caption{Comparison of clustering metrics by reduction and cluster method}\\n\")\n",
    "        f.write(\"\\\\label{tab:pivot_table}\\n\")\n",
    "        f.write(\"\\\\begin{adjustbox}{max width=\\\\textwidth}\\n\")\n",
    "        f.write(\"\\\\begin{tabular}{ll\" + \"c\" * len(pivot_table.columns) + \"}\\n\")\n",
    "        f.write(\"\\\\toprule\\n\")\n",
    "        print( pivot_table.columns)\n",
    "        # Write the column headers\n",
    "        headers = \"reduction method & cluster method & \" + \" & \".join(\n",
    "            [f\"{source}\" for source in pivot_table.columns]) + \" \\\\\\\\\\n\"\n",
    "        f.write(headers)\n",
    "        f.write(\"\\\\midrule\\n\")\n",
    "\n",
    "        # Write the table rows\n",
    "        for (reduction_method, cluster_method), row in pivot_table.iterrows():\n",
    "            f.write(f\"{reduction_method} & {cluster_method} & \")\n",
    "            row_values = []\n",
    "            for col, value in row.items():\n",
    "                if value == max_values[col]:\n",
    "                    formatted = f\"\\\\textbf{{{value:.3f}}}\"\n",
    "                elif value == second_max_values[col]:\n",
    "                    formatted = f\"\\\\textit{{{value:.3f}}}\"\n",
    "                else:\n",
    "                    formatted = f\"{value:.3f}\"\n",
    "                row_values.append(formatted)\n",
    "            f.write(\" & \".join(row_values) + \" \\\\\\\\\\n\")\n",
    "\n",
    "        f.write(\"\\\\bottomrule\\n\")\n",
    "        f.write(\"\\\\end{tabular}\\n\")\n",
    "        f.write(\"\\\\end{adjustbox}\\n\")\n",
    "        f.write(\"\\\\end{table}\\n\")\n",
    "        f.write(\"\\\\end{document}\\n\")\n",
    "\n",
    "\n",
    "# Assuming `pivot` is already created from your DataFrame:\n",
    "# pivot = df.pivot_table(...) as you described\n",
    "\n",
    "pivot_to_latex(pivot, \"pivot_table.tex\")\n",
    "# print(\"LaTeX code has been saved to 'pivot_table.tex'\")\n",
    "\n",
    "print(\"LaTeX code has been saved to 'pivot_table.tex'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>Web of science</th>\n",
       "      <th>DBpedia</th>\n",
       "      <th>Amazon</th>\n",
       "      <th>Fisheries (d)</th>\n",
       "      <th>Fisheries (s)</th>\n",
       "      <th>Ecosystems (d)</th>\n",
       "      <th>Ecosystems (s)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reduction_method</th>\n",
       "      <th>cluster_method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">PHATE</th>\n",
       "      <th>Diffusion condensation</th>\n",
       "      <td>0.005842</td>\n",
       "      <td>0.358797</td>\n",
       "      <td>0.246718</td>\n",
       "      <td>0.185601</td>\n",
       "      <td>0.207137</td>\n",
       "      <td>0.178871</td>\n",
       "      <td>0.230118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agglomerative</th>\n",
       "      <td>0.224911</td>\n",
       "      <td>0.467109</td>\n",
       "      <td>0.315135</td>\n",
       "      <td>0.210014</td>\n",
       "      <td>0.245929</td>\n",
       "      <td>0.207039</td>\n",
       "      <td>0.248099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HDBSCAN</th>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.007816</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.015402</td>\n",
       "      <td>0.018614</td>\n",
       "      <td>0.082103</td>\n",
       "      <td>0.097240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">PCA</th>\n",
       "      <th>Diffusion condensation</th>\n",
       "      <td>-0.001385</td>\n",
       "      <td>0.283691</td>\n",
       "      <td>0.246718</td>\n",
       "      <td>0.163419</td>\n",
       "      <td>0.171305</td>\n",
       "      <td>0.160698</td>\n",
       "      <td>0.199161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agglomerative</th>\n",
       "      <td>0.252200</td>\n",
       "      <td>0.379651</td>\n",
       "      <td>0.343061</td>\n",
       "      <td>0.182017</td>\n",
       "      <td>0.240366</td>\n",
       "      <td>0.146692</td>\n",
       "      <td>0.245135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HDBSCAN</th>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>-0.000073</td>\n",
       "      <td>0.055415</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.032584</td>\n",
       "      <td>0.112675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">UMAP</th>\n",
       "      <th>Diffusion condensation</th>\n",
       "      <td>0.003930</td>\n",
       "      <td>0.165275</td>\n",
       "      <td>0.212233</td>\n",
       "      <td>0.130139</td>\n",
       "      <td>0.125598</td>\n",
       "      <td>0.121873</td>\n",
       "      <td>0.133857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agglomerative</th>\n",
       "      <td>0.279785</td>\n",
       "      <td>0.418425</td>\n",
       "      <td>0.391752</td>\n",
       "      <td>0.245529</td>\n",
       "      <td>0.228249</td>\n",
       "      <td>0.228762</td>\n",
       "      <td>0.228528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HDBSCAN</th>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.058370</td>\n",
       "      <td>0.142991</td>\n",
       "      <td>0.018243</td>\n",
       "      <td>0.075198</td>\n",
       "      <td>0.205423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "source                                   Web of science   DBpedia    Amazon  \\\n",
       "reduction_method cluster_method                                               \n",
       "PHATE            Diffusion condensation        0.005842  0.358797  0.246718   \n",
       "                 Agglomerative                 0.224911  0.467109  0.315135   \n",
       "                 HDBSCAN                       0.000121  0.007816  0.000637   \n",
       "PCA              Diffusion condensation       -0.001385  0.283691  0.246718   \n",
       "                 Agglomerative                 0.252200  0.379651  0.343061   \n",
       "                 HDBSCAN                      -0.000003  0.000049 -0.000073   \n",
       "UMAP             Diffusion condensation        0.003930  0.165275  0.212233   \n",
       "                 Agglomerative                 0.279785  0.418425  0.391752   \n",
       "                 HDBSCAN                       0.000183  0.000881  0.058370   \n",
       "\n",
       "source                                   Fisheries (d)  Fisheries (s)  \\\n",
       "reduction_method cluster_method                                         \n",
       "PHATE            Diffusion condensation       0.185601       0.207137   \n",
       "                 Agglomerative                0.210014       0.245929   \n",
       "                 HDBSCAN                      0.015402       0.018614   \n",
       "PCA              Diffusion condensation       0.163419       0.171305   \n",
       "                 Agglomerative                0.182017       0.240366   \n",
       "                 HDBSCAN                      0.055415       0.000385   \n",
       "UMAP             Diffusion condensation       0.130139       0.125598   \n",
       "                 Agglomerative                0.245529       0.228249   \n",
       "                 HDBSCAN                      0.142991       0.018243   \n",
       "\n",
       "source                                   Ecosystems (d)  Ecosystems (s)  \n",
       "reduction_method cluster_method                                          \n",
       "PHATE            Diffusion condensation        0.178871        0.230118  \n",
       "                 Agglomerative                 0.207039        0.248099  \n",
       "                 HDBSCAN                       0.082103        0.097240  \n",
       "PCA              Diffusion condensation        0.160698        0.199161  \n",
       "                 Agglomerative                 0.146692        0.245135  \n",
       "                 HDBSCAN                       0.032584        0.112675  \n",
       "UMAP             Diffusion condensation        0.121873        0.133857  \n",
       "                 Agglomerative                 0.228762        0.228528  \n",
       "                 HDBSCAN                       0.075198        0.205423  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
