{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "\n",
    "# Set the target folder name you want to reach\n",
    "target_folder = \"phate-for-text\"\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Loop to move up the directory tree until we reach the target folder\n",
    "while os.path.basename(current_dir) != target_folder:\n",
    "    parent_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "    if parent_dir == current_dir:\n",
    "        # If we reach the root directory and haven't found the target, exit\n",
    "        raise FileNotFoundError(f\"{target_folder} not found in the directory tree.\")\n",
    "    current_dir = parent_dir\n",
    "\n",
    "# Change the working directory to the folder where \"phate-for-text\" is found\n",
    "os.chdir(current_dir)\n",
    "\n",
    "# Add the \"phate-for-text\" directory to sys.path\n",
    "sys.path.insert(0, current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import warnings\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import numpy as np\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_by_ari(labels, reference_labels, palette=\"tab10\"):\n",
    "    labels = np.array([str(l) if l is not None else \"None\" for l in labels])\n",
    "    reference_labels = np.array([str(l) if l is not None else \"None\" for l in reference_labels])\n",
    "\n",
    "    # Mask valid entries (exclude \"None\" for ARI calculation)\n",
    "    valid_mask = (labels != \"None\") & (reference_labels != \"None\")\n",
    "    valid_labels = labels[valid_mask]\n",
    "    valid_ref_labels = reference_labels[valid_mask]\n",
    "\n",
    "    unique_labels = sorted(set(valid_labels))\n",
    "    unique_ref_labels = sorted(set(valid_ref_labels))\n",
    "\n",
    "    # Create color palette\n",
    "    max_colors = max(len(unique_labels), len(unique_ref_labels)) + 5\n",
    "    palette_colors = sns.color_palette(palette, max_colors)\n",
    "    color_pool = [\n",
    "        f\"rgba({int(r*255)}, {int(g*255)}, {int(b*255)}, 1.0)\"\n",
    "        for r, g, b in palette_colors\n",
    "    ]\n",
    "\n",
    "    # Assign colors to reference clusters\n",
    "    ref_color_map = {}\n",
    "    used_colors = set()\n",
    "    for i, ref_label in enumerate(unique_ref_labels):\n",
    "        color = color_pool[i]\n",
    "        ref_color_map[ref_label] = color\n",
    "        used_colors.add(color)\n",
    "\n",
    "    # Compute ARI and match predicted clusters to reference clusters\n",
    "    scores = []\n",
    "    for label in unique_labels:\n",
    "        label_mask = valid_labels == label\n",
    "        for ref_label in unique_ref_labels:\n",
    "            ref_mask = valid_ref_labels == ref_label\n",
    "            ari = adjusted_rand_score(label_mask, ref_mask)\n",
    "            scores.append((ari, label, ref_label))\n",
    "    scores.sort(reverse=True)\n",
    "\n",
    "    label_to_color = {}\n",
    "    matched_labels = set()\n",
    "    matched_refs = set()\n",
    "\n",
    "    for ari, label, ref_label in scores:\n",
    "        if label in matched_labels or ref_label in matched_refs:\n",
    "            continue\n",
    "        label_to_color[label] = ref_color_map[ref_label]\n",
    "        matched_labels.add(label)\n",
    "        matched_refs.add(ref_label)\n",
    "\n",
    "    # Assign unmatched labels new colors\n",
    "    for label in unique_labels:\n",
    "        if label not in label_to_color:\n",
    "            unused_colors = [c for c in color_pool if c not in used_colors]\n",
    "            label_to_color[label] = unused_colors[0] if unused_colors else \"rgba(0,0,0,0.8)\"\n",
    "            used_colors.add(label_to_color[label])\n",
    "\n",
    "    # Always assign 'None' label grey transparent color\n",
    "    label_to_color[\"None\"] = \"rgba(0,0,0,0.2)\"\n",
    "\n",
    "    # Final per-sample color list, with OVERRIDE if reference is 'None'\n",
    "    final_colors = [\n",
    "        label_to_color[\"None\"] if ref == \"None\" else label_to_color.get(pred, \"rgba(0,0,0,0.8)\")\n",
    "        for pred, ref in zip(labels, reference_labels)\n",
    "    ]\n",
    "\n",
    "    return label_to_color, final_colors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_topic_map(embedding, labels, topic_names=None, palette=\"tab10\", plot_3d=True, title=\"Topic Map\", reference_labels=None,pt_size=4):\n",
    "    labels = [str(label) if label is not None else \"None\" for label in labels]\n",
    "\n",
    "    # Color assignment\n",
    "    if reference_labels is not None:\n",
    "        label_to_color, colors = align_labels_by_ari(labels, reference_labels, palette=palette)\n",
    "    else:\n",
    "        unique_labels = sorted(set(label for label in labels if label != \"None\"))\n",
    "        palette_colors = sns.color_palette(palette, len(unique_labels))\n",
    "        label_to_color = {\n",
    "            label: f\"rgba({int(r*255)}, {int(g*255)}, {int(b*255)}, 1.0)\"\n",
    "            for label, (r, g, b) in zip(unique_labels, palette_colors)\n",
    "        }\n",
    "        label_to_color[\"None\"] = \"rgba(0,0,0,0.2)\"\n",
    "\n",
    "    colors = [label_to_color.get(label, \"rgba(0,0,0,0.2)\") for label in labels]\n",
    "\n",
    "    if topic_names is not None:\n",
    "        text = [f\"Topic: {t}<br>Label: {l}\" for t, l in zip(topic_names, labels)]\n",
    "    else:\n",
    "        text = [f\"Label: {l}\" for l in labels]\n",
    "\n",
    "    if plot_3d:\n",
    "        trace = go.Scatter3d(\n",
    "            x=embedding[:, 0], y=embedding[:, 1], z=embedding[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(size=pt_size, color=colors),\n",
    "            text=text,\n",
    "            hoverinfo='text'\n",
    "        )\n",
    "        layout = go.Layout(\n",
    "            title=dict(text=title, x=0.5),\n",
    "            scene=dict(\n",
    "                xaxis=dict(showticklabels=False),\n",
    "                yaxis=dict(showticklabels=False),\n",
    "                zaxis=dict(showticklabels=False)\n",
    "            ),\n",
    "            width=800, height=600, showlegend=False\n",
    "        )\n",
    "    else:\n",
    "        trace = go.Scatter(\n",
    "            x=embedding[:, 0], y=embedding[:, 1],\n",
    "            mode='markers',\n",
    "            marker=dict(size=pt_size, color=colors),\n",
    "            text=text,\n",
    "            hoverinfo='text'\n",
    "        )\n",
    "        layout = go.Layout(\n",
    "            title=dict(text=title, x=0.5),\n",
    "            xaxis=dict(showticklabels=False),\n",
    "            yaxis=dict(showticklabels=False),\n",
    "            width=800, height=600,\n",
    "            showlegend=False\n",
    "        )\n",
    "\n",
    "    fig = go.Figure(data=[trace], layout=layout)\n",
    "    return fig, label_to_color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_legend_only_figure(label_to_color, marker_size=10, font_size=12):\n",
    "    traces = []\n",
    "    for label, color in label_to_color.items():\n",
    "        if str(label) == 'nan':\n",
    "            continue\n",
    "        trace = go.Scatter(\n",
    "            x=[None],\n",
    "            y=[None],\n",
    "            mode='markers',\n",
    "            marker=dict(size=marker_size, color=color),\n",
    "            name=str(label),\n",
    "            showlegend=True\n",
    "        )\n",
    "        traces.append(trace)\n",
    "\n",
    "    layout = go.Layout(\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            x=0,\n",
    "            y=1,\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=font_size,\n",
    "                color='black'\n",
    "            )\n",
    "        ),\n",
    "        font=dict(  # global font (e.g., title, annotations)\n",
    "            family='Times New Roman',\n",
    "            size=font_size,\n",
    "            color='black'\n",
    "        ),\n",
    "        xaxis=dict(visible=False),\n",
    "        yaxis=dict(visible=False),\n",
    "        width=100,\n",
    "        height=100,\n",
    "        margin=dict(l=0, r=0, t=0, b=0),\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white',\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=traces, layout=layout)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = \"text-embedding-3-large\"\n",
    "embed = np.load(f'{embedding_model}_reduced_embeddings/phate_embedding_Energy, Ecosystems, and Humans_hierarchy_t1.0_maxsub3_depth5_synonyms10_noise0.25_random_decay20_n_components300_tauto.npy')\n",
    "topic_df= pd.read_csv(\"data_generation/generated_data/Energy, Ecosystems, and Humans_hierarchy_t1.0_maxsub3_depth5_synonyms10_noise0.25_random.csv\")\n",
    "colors = topic_df['category 0']\n",
    "labels = topic_df['topic']\n",
    "shuffle_idx = np.random.RandomState(seed=42).permutation(len(topic_df))\n",
    "colors = colors.replace('was','None')[shuffle_idx]\n",
    "colors = colors.replace(np.nan,'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, _=plot_topic_map(embed, colors, topic_names=topic_df['topic'], palette=\"tab10\", plot_3d=False, title='PHATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.write_html('Ecosystem(d).html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {\n",
    "    # Web of Science\n",
    "    \"Web of science_PHATE\": f\"{embedding_model}_reduced_embeddings/PHATE_WOS_embed.npy\",\n",
    "    \"Web of science_PCA\": f\"{embedding_model}_reduced_embeddings/PCA_WOS_embed.npy\",\n",
    "    \"Web of science_UMAP\": f\"{embedding_model}_reduced_embeddings/UMAP_WOS_embed_new.npy\",\n",
    "    \"Web of science_T-SNE\": f\"{embedding_model}_reduced_embeddings/tSNE_WOS_embed.npy\",\n",
    "\n",
    "    # DBpedia\n",
    "    \"DBpedia_PHATE\": f\"{embedding_model}_reduced_embeddings/dbpedia_phate_embed.npy\",\n",
    "    \"DBpedia_PCA\": f\"{embedding_model}_reduced_embeddings/PCA_dbpedia_embed.npy\",\n",
    "    \"DBpedia_UMAP\": f\"{embedding_model}_reduced_embeddings/UMAP_dbpedia_embed_new.npy\",\n",
    "    \"DBpedia_T-SNE\": f\"{embedding_model}_reduced_embeddings/tSNE_dbpedia_embed.npy\",\n",
    "\n",
    "    # Amazon\n",
    "    \"Amazon_PHATE\": f\"{embedding_model}_reduced_embeddings/PHATE_amz_embed.npy\",\n",
    "    \"Amazon_PCA\": f\"{embedding_model}_reduced_embeddings/PCA_amz_embed.npy\",\n",
    "    \"Amazon_UMAP\": f\"{embedding_model}_reduced_embeddings/UMAP_amz_embed_new.npy\",\n",
    "    \"Amazon_T-SNE\": f\"{embedding_model}_reduced_embeddings/tSNE_amz_embed.npy\",\n",
    "\n",
    "    # Fisheries (deep)\n",
    "    \"Fisheries (d)_PHATE\": f\"{embedding_model}_reduced_embeddings/phate_embedding_Offshore energy impacts on fisheries_hierarchy_t1.0_maxsub3_depth5_synonyms10_noise0.25_random_decay20_n_components300_tauto.npy\",\n",
    "    \"Fisheries (d)_PCA\": f\"{embedding_model}_reduced_embeddings/PCA_embedding_Offshore energy impacts on fisheries_hierarchy_t1.0_maxsub3_depth5_synonyms10_noise0.25_random_n_components300.npy\",\n",
    "    \"Fisheries (d)_UMAP\": f\"{embedding_model}_reduced_embeddings/UMAP_embedding_Offshore energy impacts on fisheries_hierarchy_t1.0_maxsub3_depth5_synonyms10_noise0.25_random_n_components300.npy\",\n",
    "    \"Fisheries (d)_T-SNE\": f\"{embedding_model}_reduced_embeddings/tSNE_embedding_Offshore energy impacts on fisheries_hierarchy_t1.0_maxsub3_depth5_synonyms10_noise0.25_random_n_components300.npy\",\n",
    "\n",
    "    # Fisheries (shallow)\n",
    "    \"Fisheries (s)_PHATE\": f\"{embedding_model}_reduced_embeddings/phate_embedding_Offshore energy impacts on fisheries_hierarchy_t1.0_maxsub5_depth3_synonyms10_noise0.25_random_decay20_n_components300_tauto.npy\",\n",
    "    \"Fisheries (s)_PCA\": f\"{embedding_model}_reduced_embeddings/PCA_embedding_Offshore energy impacts on fisheries_hierarchy_t1.0_maxsub5_depth3_synonyms10_noise0.25_random_n_components300.npy\",\n",
    "    \"Fisheries (s)_UMAP\": f\"{embedding_model}_reduced_embeddings/UMAP_embedding_Offshore energy impacts on fisheries_hierarchy_t1.0_maxsub5_depth3_synonyms10_noise0.25_random_n_components300.npy\",\n",
    "    \"Fisheries (s)_T-SNE\": f\"{embedding_model}_reduced_embeddings/tSNE_embedding_Offshore energy impacts on fisheries_hierarchy_t1.0_maxsub5_depth3_synonyms10_noise0.25_random_n_components300.npy\",\n",
    "\n",
    "    # Ecosystems (deep)\n",
    "    \"Ecosystems (d)_PHATE\": f\"{embedding_model}_reduced_embeddings/phate_embedding_Energy, Ecosystems, and Humans_hierarchy_t1.0_maxsub3_depth5_synonyms10_noise0.25_random_decay20_n_components300_tauto.npy\",\n",
    "    \"Ecosystems (d)_PCA\": f\"{embedding_model}_reduced_embeddings/PCA_embedding_Energy, Ecosystems, and Humans_hierarchy_t1.0_maxsub3_depth5_synonyms10_noise0.25_random_n_components300.npy\",\n",
    "    \"Ecosystems (d)_UMAP\": f\"{embedding_model}_reduced_embeddings/UMAP_embedding_Energy, Ecosystems, and Humans_hierarchy_t1.0_maxsub3_depth5_synonyms10_noise0.25_random_n_components300.npy\",\n",
    "    \"Ecosystems (d)_T-SNE\": f\"{embedding_model}_reduced_embeddings/tSNE_embedding_Energy, Ecosystems, and Humans_hierarchy_t1.0_maxsub3_depth5_synonyms10_noise0.25_random_n_components300.npy\",\n",
    "\n",
    "    # Ecosystems (shallow)\n",
    "    \"Ecosystems (s)_PHATE\": f\"{embedding_model}_reduced_embeddings/phate_embedding_Energy, Ecosystems, and Humans_hierarchy_t1.0_maxsub5_depth3_synonyms10_noise0.25_random_decay20_n_components300_tauto.npy\",\n",
    "    \"Ecosystems (s)_PCA\": f\"{embedding_model}_reduced_embeddings/PCA_embedding_Energy, Ecosystems, and Humans_hierarchy_t1.0_maxsub5_depth3_synonyms10_noise0.25_random_n_components300.npy\",\n",
    "    \"Ecosystems (s)_UMAP\": f\"{embedding_model}_reduced_embeddings/UMAP_embedding_Energy, Ecosystems, and Humans_hierarchy_t1.0_maxsub5_depth3_synonyms10_noise0.25_random_n_components300.npy\",\n",
    "    \"Ecosystems (s)_T-SNE\": f\"{embedding_model}_reduced_embeddings/tSNE_embedding_Energy, Ecosystems, and Humans_hierarchy_t1.0_maxsub5_depth3_synonyms10_noise0.25_random_n_components300.npy\",\n",
    "}\n",
    "\n",
    "\n",
    "data_files = {\n",
    "    # Hierarchical: Ecosystems\n",
    "    \"Ecosystems (d)\": \"data_generation/generated_data/Energy, Ecosystems, and Humans_hierarchy_t1.0_maxsub3_depth5_synonyms10_noise0.25_random.csv\",\n",
    "    \"Ecosystems (s)\": \"data_generation/generated_data/Energy, Ecosystems, and Humans_hierarchy_t1.0_maxsub5_depth3_synonyms10_noise0.25_random.csv\",\n",
    "\n",
    "    # Hierarchical: Fisheries\n",
    "    \"Fisheries (d)\": \"data_generation/generated_data/Offshore energy impacts on fisheries_hierarchy_t1.0_maxsub3_depth5_synonyms10_noise0.25_random.csv\",\n",
    "    \"Fisheries (s)\": \"data_generation/generated_data/Offshore energy impacts on fisheries_hierarchy_t1.0_maxsub5_depth3_synonyms10_noise0.25_random.csv\",\n",
    "\n",
    "    # Flat data sources\n",
    "    \"Amazon\": \"data/amazon/amz_data.csv\",\n",
    "    \"DBpedia\": \"data/dbpedia/DBP_wiki_data.csv\",\n",
    "    \"Web of science\": \"data/WebOfScience/Meta-data/Data.xlsx\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract unique row and column labels\n",
    "row_labels = []\n",
    "col_labels = []\n",
    "\n",
    "# Go through dataset_dict and extract the row and column labels while maintaining their original order\n",
    "for k in dataset_dict:\n",
    "    row_label, col_label = k.split(\"_\")[0], k.split(\"_\")[1]\n",
    "    if row_label not in row_labels:\n",
    "        row_labels.append(row_label)\n",
    "    if col_label not in col_labels:\n",
    "        col_labels.append(col_label)\n",
    "\n",
    "content_cols = len(col_labels)\n",
    "\n",
    "# Equal widths for content columns\n",
    "equal_width = 1.0\n",
    "column_widths = [equal_width] * content_cols\n",
    "\n",
    "# Scale all widths so they sum to 1 (required by Plotly)\n",
    "total_width = sum(column_widths)\n",
    "normalized_widths = [w / total_width for w in column_widths]\n",
    "\n",
    "# Initialize subplot grid\n",
    "fig = make_subplots(\n",
    "    rows=len(row_labels),\n",
    "    cols=content_cols,\n",
    "    column_widths=normalized_widths,\n",
    "    horizontal_spacing=0.01,\n",
    "    vertical_spacing=0.03,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    width=800 * len(col_labels),  # ~300 px per subplot\n",
    "    height=600 * len(row_labels), # ~300 px per row\n",
    "    showlegend=False,\n",
    "    margin=dict(l=20, r=20, t=20, b=20),\n",
    ")\n",
    "\n",
    "# Map row and column positions\n",
    "row_map = {label: i + 1 for i, label in enumerate(row_labels)}\n",
    "col_map = {label: j + 1 for j, label in enumerate(col_labels)}\n",
    "\n",
    "latest_colors_by_row = {}\n",
    "for key, title in dataset_dict.items():\n",
    "    print(key)\n",
    "    row_key, col_key = key.split(\"_\")\n",
    "    i = row_map[row_key]\n",
    "    j = col_map[col_key]\n",
    "\n",
    "    topic_file = data_files[row_key]\n",
    "    embedding_file = title\n",
    "    if topic_file.endswith('.csv'):\n",
    "        df = pd.read_csv(topic_file)\n",
    "    else:\n",
    "        df = pd.read_excel(topic_file)\n",
    "\n",
    "    if row_key == 'Amazon':\n",
    "        colors = df['category_0']\n",
    "    elif row_key == 'DBpedia':\n",
    "        colors = df['l1']\n",
    "    elif row_key == 'Web of science':\n",
    "        colors = df['Domain']\n",
    "    else:\n",
    "        colors = df['category 0'].replace('was', None).replace(np.nan, None)\n",
    "\n",
    "    embed = np.load(embedding_file)\n",
    "    shuffle_idx = np.random.RandomState(seed=42).permutation(len(df))\n",
    "    embed = embed\n",
    "    colors = colors.iloc[shuffle_idx]\n",
    "\n",
    "    if len(df) > 10000:\n",
    "        pt_size = 3\n",
    "    else:\n",
    "        pt_size = 6\n",
    "\n",
    "    fig_topic, label_to_color = plot_topic_map(embed, colors, plot_3d=False, title=\"\", palette=\"tab10\", pt_size=pt_size)\n",
    "\n",
    "    latest_colors_by_row[row_key] = label_to_color\n",
    "\n",
    "    if 'Generated' not in topic_file:\n",
    "        label_to_color.pop('None', None)\n",
    "\n",
    "    # Add the trace(s) from the topic map to the subplot\n",
    "    for trace in fig_topic.data:\n",
    "        fig.add_trace(trace, row=i, col=j)\n",
    "# Adjust margins to provide more space for titles\n",
    "fig.update_layout(\n",
    "    margin=dict(l=450, r=20, t=100, b=20),  # More space around the plot for titles\n",
    ")\n",
    "\n",
    "# Add column titles (top of each column)\n",
    "for j, col_label in enumerate(col_labels):\n",
    "    xref = f\"x{j+1} domain\" if j + 1 > 1 else \"paper\"\n",
    "    x= .5 if j + 1 > 1 else .095\n",
    "    fig.add_annotation(\n",
    "        dict(\n",
    "            text=col_label,\n",
    "            xref=xref,\n",
    "            yref=\"paper\",\n",
    "            x=x,\n",
    "            y=1.015,\n",
    "            showarrow=False,\n",
    "            font=dict(size=48),\n",
    "            align=\"center\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Add row titles (left of each row)\n",
    "for i, row_label in enumerate(row_labels):\n",
    "    axis_index = i * content_cols + 1  # Index of the first subplot in the row\n",
    "    yref = f\"y{axis_index} domain\" if axis_index > 1 else \"paper\"\n",
    "    y= .5 if i + 1 > 1 else .95\n",
    "    fig.add_annotation(\n",
    "        dict(\n",
    "            text=row_label,\n",
    "            xref=\"paper\",\n",
    "            yref=yref,\n",
    "            x=-0.15,  # Slightly to the left of the plots\n",
    "            y=y,  # Centered within that domain\n",
    "            showarrow=False,\n",
    "            font=dict(size=48),\n",
    "            align=\"right\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "for i in range(1, len(row_labels) + 1):\n",
    "    for j in range(1, len(col_labels) + 1):\n",
    "        fig.update_xaxes(showticklabels=False, ticks=\"\", row=i, col=j)\n",
    "        fig.update_yaxes(showticklabels=False, ticks=\"\", row=i, col=j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"all_embeddings_subplot.png\", scale=4\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EPA visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data/epa/epa_embed.npy')\n",
    "\n",
    "labels = np.load('data/epa/epa_labels.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = \"MiniLM-L6-v2\"\n",
    "\n",
    "embedding_methods = {}\n",
    "embedding_methods[\"PHATE\"]  =np.load(f\"{embedding_model}_reduced_embeddings/PHATE_epa_embed_top20.npy\")\n",
    "embedding_methods[\"UMAP\"]=np.load(f\"{embedding_model}_reduced_embeddings/UMAP_epa_embed_top20.npy\")\n",
    "embedding_methods['PCA']=np.load(f\"{embedding_model}_reduced_embeddings/PCA_epa_embed_top20.npy\")\n",
    "embedding_methods['T-SNE']=np.load(f\"{embedding_model}_reduced_embeddings/tSNE_epa_embedtop20.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create a 2x2 subplot figure\n",
    "fig_combined = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=list(embedding_methods.keys()),\n",
    "    specs=[[{\"type\": \"scatter\"}]*2]*2,\n",
    "    vertical_spacing=0.05,\n",
    "    horizontal_spacing=.05,\n",
    "    \n",
    ")\n",
    "\n",
    "row_col_map = [(1, 1), (1, 2), (2, 1), (2, 2)]\n",
    "\n",
    "for (i, (method_name, data)) in zip(row_col_map, embedding_methods.items()):\n",
    "    row, col = i\n",
    "    # Generate the topic map plot\n",
    "\n",
    "    fig_topic, label_to_color = plot_topic_map(\n",
    "        data, labels,plot_3d=False, title=None, palette=\"tab20\"\n",
    "    )\n",
    "    # fig_topic.write_image(f'{method_name}_epa.png',scale=5)\n",
    "\n",
    "    # Add each trace from fig_topic into the corresponding subplot\n",
    "    for trace in fig_topic.data:\n",
    "        trace\n",
    "        fig_combined.add_trace(trace, row=row, col=col)\n",
    "\n",
    "axis_style = dict(showticklabels=False)\n",
    "\n",
    "fig_combined.update_layout(\n",
    "    height = 900,\n",
    "    width = 1200,\n",
    "    # margin=dict(t=5),\n",
    "    title_font_size=64,\n",
    "    xaxis=axis_style,\n",
    "    xaxis2=axis_style,\n",
    "    xaxis3=axis_style,\n",
    "    xaxis4=axis_style,\n",
    "    yaxis=axis_style,\n",
    "    yaxis2=axis_style,\n",
    "    yaxis3=axis_style,\n",
    "    yaxis4=axis_style,\n",
    "    showlegend=False,\n",
    "    \n",
    ")\n",
    "for annotation in fig_combined['layout']['annotations']:\n",
    "    annotation['font'] = dict(size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_combined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
