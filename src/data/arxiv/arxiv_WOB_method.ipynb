{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arXiv Version (Structured Like Your WOS Pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load arXiv Metadata (Streaming – Don’t Load 1.5GB Fully)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2951540it [00:21, 134433.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The evolution of the Earth-Moon system based o...</td>\n",
       "      <td>physics.gen-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Convergence of the discrete dipole approximati...</td>\n",
       "      <td>physics.optics physics.comp-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Convergence of the discrete dipole approximati...</td>\n",
       "      <td>physics.optics physics.comp-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The discrete dipole approximation for simulati...</td>\n",
       "      <td>physics.optics physics.comp-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The discrete dipole approximation: an overview...</td>\n",
       "      <td>physics.optics physics.comp-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924080</th>\n",
       "      <td>Variational methods, multiprecision and nonrel...</td>\n",
       "      <td>physics.atom-ph physics.comp-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924081</th>\n",
       "      <td>Effective interaction between helical bio-mole...</td>\n",
       "      <td>physics.bio-ph physics.chem-ph physics.comp-ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924082</th>\n",
       "      <td>Atom-optics hologram in the time domain   The ...</td>\n",
       "      <td>physics.atom-ph physics.optics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924083</th>\n",
       "      <td>A Second-Order Stochastic Leap-Frog Algorithm ...</td>\n",
       "      <td>physics.comp-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924084</th>\n",
       "      <td>Analytical Structure Matching and Very Precise...</td>\n",
       "      <td>physics.atom-ph</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>924085 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    topic  \\\n",
       "0       The evolution of the Earth-Moon system based o...   \n",
       "1       Convergence of the discrete dipole approximati...   \n",
       "2       Convergence of the discrete dipole approximati...   \n",
       "3       The discrete dipole approximation for simulati...   \n",
       "4       The discrete dipole approximation: an overview...   \n",
       "...                                                   ...   \n",
       "924080  Variational methods, multiprecision and nonrel...   \n",
       "924081  Effective interaction between helical bio-mole...   \n",
       "924082  Atom-optics hologram in the time domain   The ...   \n",
       "924083  A Second-Order Stochastic Leap-Frog Algorithm ...   \n",
       "924084  Analytical Structure Matching and Very Precise...   \n",
       "\n",
       "                                               categories  \n",
       "0                                          physics.gen-ph  \n",
       "1                          physics.optics physics.comp-ph  \n",
       "2                          physics.optics physics.comp-ph  \n",
       "3                          physics.optics physics.comp-ph  \n",
       "4                          physics.optics physics.comp-ph  \n",
       "...                                                   ...  \n",
       "924080                    physics.atom-ph physics.comp-ph  \n",
       "924081  physics.bio-ph physics.chem-ph physics.comp-ph...  \n",
       "924082                     physics.atom-ph physics.optics  \n",
       "924083                                    physics.comp-ph  \n",
       "924084                                    physics.atom-ph  \n",
       "\n",
       "[924085 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_path = \"../../../../arxiv-metadata-oai-snapshot.json\"\n",
    "\n",
    "\n",
    "\n",
    "records = []\n",
    "\n",
    "# Stream safely (important for large file)\n",
    "with open(file_path, \"r\") as f:\n",
    "    for line in tqdm(f):\n",
    "        paper = json.loads(line)\n",
    "        \n",
    "        # Only keep CS + Physics (like taxonomy goal)\n",
    "        if paper[\"categories\"].startswith((\"cs.\", \"physics.\")):\n",
    "            records.append({\n",
    "                \"topic\": paper[\"title\"] + \" \" + paper[\"abstract\"],\n",
    "                \"categories\": paper[\"categories\"]\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_arxiv = pd.DataFrame(records)\n",
    "df_arxiv.head()\n",
    "df_arxiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arXiv Dataset Subsampling\n",
    "The full arXiv metadata snapshot contains over 900,000 physics-related records, which is computationally expensive to process for embedding generation and dimensionality reduction. Generating embeddings for the entire dataset would significantly increase runtime, memory usage, and API costs without providing meaningful additional evaluation benefits for this study.\n",
    "To ensure computational feasibility while preserving hierarchical diversity, we randomly sampled 30,000 papers from the filtered Physics subset. This sample size is sufficient to:\n",
    "Maintain a rich hierarchical structure across subject categories\n",
    "Enable robust clustering evaluation\n",
    "Provide statistically meaningful benchmarking results\n",
    "Keep embedding and PHATE computation tractable\n",
    "The sampling procedure was performed using a fixed random seed to ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Semantic Agreement Enables Efficient Open-Ende...</td>\n",
       "      <td>cs.CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scheduling in Grid Computing Environment   Sch...</td>\n",
       "      <td>cs.DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taking off the Rose-Tinted Glasses: A Critical...</td>\n",
       "      <td>cs.LG cs.CR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Traffic Performance Score for Measuring the Im...</td>\n",
       "      <td>physics.soc-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SueNes: A Weakly Supervised Approach to Evalua...</td>\n",
       "      <td>cs.CL cs.IR cs.LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>Improving Neural Machine Translation by Multi-...</td>\n",
       "      <td>cs.CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>Strong Exciton-Vibrational Coupling in Molecul...</td>\n",
       "      <td>physics.chem-ph quant-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>Duality of generalized twisted Reed-Solomon co...</td>\n",
       "      <td>cs.IT math.IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>Non-consensus opinion models on complex networ...</td>\n",
       "      <td>physics.soc-ph cs.SI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>Energy-limited Joint Source--Channel Coding vi...</td>\n",
       "      <td>cs.IT eess.SP math.IT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   topic  \\\n",
       "0      Semantic Agreement Enables Efficient Open-Ende...   \n",
       "1      Scheduling in Grid Computing Environment   Sch...   \n",
       "2      Taking off the Rose-Tinted Glasses: A Critical...   \n",
       "3      Traffic Performance Score for Measuring the Im...   \n",
       "4      SueNes: A Weakly Supervised Approach to Evalua...   \n",
       "...                                                  ...   \n",
       "29995  Improving Neural Machine Translation by Multi-...   \n",
       "29996  Strong Exciton-Vibrational Coupling in Molecul...   \n",
       "29997  Duality of generalized twisted Reed-Solomon co...   \n",
       "29998  Non-consensus opinion models on complex networ...   \n",
       "29999  Energy-limited Joint Source--Channel Coding vi...   \n",
       "\n",
       "                     categories  \n",
       "0                         cs.CL  \n",
       "1                         cs.DC  \n",
       "2                   cs.LG cs.CR  \n",
       "3                physics.soc-ph  \n",
       "4             cs.CL cs.IR cs.LG  \n",
       "...                         ...  \n",
       "29995                     cs.CL  \n",
       "29996  physics.chem-ph quant-ph  \n",
       "29997             cs.IT math.IT  \n",
       "29998      physics.soc-ph cs.SI  \n",
       "29999     cs.IT eess.SP math.IT  \n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arxiv = df_arxiv.sample(30000, random_state=42).reset_index(drop=True)\n",
    "df_arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                    topic  \\\n",
       "0      Semantic Agreement Enables Efficient Open-Ende...   \n",
       "1      Scheduling in Grid Computing Environment   Sch...   \n",
       "2      Taking off the Rose-Tinted Glasses: A Critical...   \n",
       "3      Traffic Performance Score for Measuring the Im...   \n",
       "4      SueNes: A Weakly Supervised Approach to Evalua...   \n",
       "...                                                  ...   \n",
       "29995  Improving Neural Machine Translation by Multi-...   \n",
       "29996  Strong Exciton-Vibrational Coupling in Molecul...   \n",
       "29997  Duality of generalized twisted Reed-Solomon co...   \n",
       "29998  Non-consensus opinion models on complex networ...   \n",
       "29999  Energy-limited Joint Source--Channel Coding vi...   \n",
       "\n",
       "                     categories  \n",
       "0                         cs.CL  \n",
       "1                         cs.DC  \n",
       "2                   cs.LG cs.CR  \n",
       "3                physics.soc-ph  \n",
       "4             cs.CL cs.IR cs.LG  \n",
       "...                         ...  \n",
       "29995                     cs.CL  \n",
       "29996  physics.chem-ph quant-ph  \n",
       "29997             cs.IT math.IT  \n",
       "29998      physics.soc-ph cs.SI  \n",
       "29999     cs.IT eess.SP math.IT  \n",
       "\n",
       "[30000 rows x 2 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arxiv.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Primary Category + Top Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>category 0</th>\n",
       "      <th>category 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Semantic Agreement Enables Efficient Open-Ende...</td>\n",
       "      <td>cs</td>\n",
       "      <td>cs.CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scheduling in Grid Computing Environment   Sch...</td>\n",
       "      <td>cs</td>\n",
       "      <td>cs.DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taking off the Rose-Tinted Glasses: A Critical...</td>\n",
       "      <td>cs</td>\n",
       "      <td>cs.LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Traffic Performance Score for Measuring the Im...</td>\n",
       "      <td>physics</td>\n",
       "      <td>physics.soc-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SueNes: A Weakly Supervised Approach to Evalua...</td>\n",
       "      <td>cs</td>\n",
       "      <td>cs.CL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               topic category 0  \\\n",
       "0  Semantic Agreement Enables Efficient Open-Ende...         cs   \n",
       "1  Scheduling in Grid Computing Environment   Sch...         cs   \n",
       "2  Taking off the Rose-Tinted Glasses: A Critical...         cs   \n",
       "3  Traffic Performance Score for Measuring the Im...    physics   \n",
       "4  SueNes: A Weakly Supervised Approach to Evalua...         cs   \n",
       "\n",
       "       category 1  \n",
       "0           cs.CL  \n",
       "1           cs.DC  \n",
       "2           cs.LG  \n",
       "3  physics.soc-ph  \n",
       "4           cs.CL  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_categories(cat_string):\n",
    "    primary = cat_string.split()[0]  # first category\n",
    "    top_level = primary.split('.')[0]\n",
    "    return top_level, primary\n",
    "\n",
    "df_arxiv[[\"category 0\", \"category 1\"]] = df_arxiv[\"categories\"].apply(\n",
    "    lambda x: pd.Series(extract_categories(x))\n",
    ")\n",
    "\n",
    "df_arxiv = df_arxiv[[\"topic\", \"category 0\", \"category 1\"]]\n",
    "df_arxiv.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Embeddings (Same as WOS)\n",
    "Important: 30k embeddings with text-embedding-3-large will cost money.\n",
    "If cost is a concern, use \"text-embedding-3-small\" for arXiv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate GPT Embeddings for arXiv (30k Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.13.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install OpenAI (Correct Way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.13.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do NOT Use dotenv Right Now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"Somekey\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching GPT embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.39s/batch]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = get_embeddings(df_arxiv[\"topic\"].tolist()[:5])\n",
    "len(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_embeddings(texts, model=\"text-embedding-3-small\"):\n",
    "    batch_size = 200\n",
    "    embeddings = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Fetching GPT embeddings\", unit=\"batch\"):\n",
    "        batch = texts[i : i + batch_size]\n",
    "        response = client.embeddings.create(input=batch, model=model)\n",
    "        batch_embeddings = [entry.embedding for entry in response.data]\n",
    "        embeddings.extend(batch_embeddings)\n",
    "\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching GPT embeddings:  27%|██▋       | 40/150 [01:36<04:26,  2.42s/batch]\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Request too large for text-embedding-3-large in organization org-wGEUWom3eHxPOUq8KfncOLIs on tokens per min (TPM): Limit 40000, Requested 60066. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m embedding_model = \u001b[33m\"\u001b[39m\u001b[33mtext-embedding-3-large\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m embedding_list = \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf_arxiv\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtopic\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_model\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m embedding_array = np.array(embedding_list, dtype=np.float32)\n\u001b[32m     10\u001b[39m np.save(\u001b[33m\"\u001b[39m\u001b[33mgpt_embeddings/arxiv_embed.npy\u001b[39m\u001b[33m\"\u001b[39m, embedding_array)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mget_embeddings\u001b[39m\u001b[34m(texts, model)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(texts), batch_size), desc=\u001b[33m\"\u001b[39m\u001b[33mFetching GPT embeddings\u001b[39m\u001b[33m\"\u001b[39m, unit=\u001b[33m\"\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      8\u001b[39m     batch = texts[i : i + batch_size]\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     batch_embeddings = [entry.embedding \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m response.data]\n\u001b[32m     11\u001b[39m     embeddings.extend(batch_embeddings)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/openai/resources/embeddings.py:132\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    127\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    128\u001b[39m             ).tolist()\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:1297\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, content, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1288\u001b[39m     warnings.warn(\n\u001b[32m   1289\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing raw bytes as `body` is deprecated and will be removed in a future version. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1290\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease pass raw bytes via the `content` parameter instead.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1291\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m   1292\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m   1293\u001b[39m     )\n\u001b[32m   1294\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1295\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, content=content, files=to_httpx_files(files), **options\n\u001b[32m   1296\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1297\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:1070\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1067\u001b[39m             err.response.read()\n\u001b[32m   1069\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1070\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1072\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'Request too large for text-embedding-3-large in organization org-wGEUWom3eHxPOUq8KfncOLIs on tokens per min (TPM): Limit 40000, Requested 60066. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "embedding_model = \"text-embedding-3-large\"\n",
    "\n",
    "embedding_list = get_embeddings(\n",
    "    df_arxiv[\"topic\"].tolist(),\n",
    "    model=embedding_model\n",
    ")\n",
    "\n",
    "embedding_array = np.array(embedding_list, dtype=np.float32)\n",
    "\n",
    "np.save(\"gpt_embeddings/arxiv_embed.npy\", embedding_array)\n",
    "\n",
    "embedding_array.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
