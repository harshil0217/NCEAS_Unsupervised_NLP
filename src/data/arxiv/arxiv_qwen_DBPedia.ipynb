{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: done\n",
      "Channels:\n",
      " - defaults\n",
      " - conda-forge\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - numpy=2.2\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    networkx-3.6.1             |  py312hca03da5_0         3.1 MB\n",
      "    numpy-2.2.5                |  py312h40d09ce_2          11 KB\n",
      "    numpy-base-2.2.5           |  py312h855c928_2         6.1 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         9.2 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  networkx                              3.3-py312hca03da5_0 --> 3.6.1-py312hca03da5_0 \n",
      "  numpy                              1.26.4-py312h901140f_1 --> 2.2.5-py312h40d09ce_2 \n",
      "  numpy-base                         1.26.4-py312hae06d03_1 --> 2.2.5-py312h855c928_2 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "numpy-base-2.2.5     | 6.1 MB    |                                       |   0% \n",
      "networkx-3.6.1       | 3.1 MB    |                                       |   0% \u001b[A\n",
      "\n",
      "numpy-2.2.5          | 11 KB     |                                       |   0% \u001b[A\u001b[A\n",
      "networkx-3.6.1       | 3.1 MB    | 1                                     |   1% \u001b[A\n",
      "\n",
      "numpy-2.2.5          | 11 KB     | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "numpy-2.2.5          | 11 KB     | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "numpy-base-2.2.5     | 6.1 MB    |                                       |   0% \u001b[A\u001b[A\n",
      "numpy-base-2.2.5     | 6.1 MB    | ##1                                   |   6% \u001b[A\n",
      "numpy-base-2.2.5     | 6.1 MB    | ####5                                 |  12% \u001b[A\n",
      "numpy-base-2.2.5     | 6.1 MB    | #######2                              |  20% \u001b[A\n",
      "numpy-base-2.2.5     | 6.1 MB    | #########4                            |  25% \u001b[A\n",
      "numpy-base-2.2.5     | 6.1 MB    | ###################4                  |  53% \u001b[A\n",
      "networkx-3.6.1       | 3.1 MB    | ##################################### | 100% \u001b[A\n",
      "                                                                                \u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install numpy=2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sukainaalkhalidy/Desktop/CMSE 495 capstone/NCEAS_Unsupervised_NLP/src/data/arxiv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root set to: /Users/sukainaalkhalidy/Desktop/CMSE 495 capstone/NCEAS_Unsupervised_NLP\n",
      "src added to path: /Users/sukainaalkhalidy/Desktop/CMSE 495 capstone/NCEAS_Unsupervised_NLP/src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Move up until we reach project root\n",
    "target_folder = \"NCEAS_Unsupervised_NLP\"\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "while os.path.basename(current_dir) != target_folder:\n",
    "    parent_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "    if parent_dir == current_dir:\n",
    "        raise FileNotFoundError(f\"{target_folder} not found in directory tree.\")\n",
    "    current_dir = parent_dir\n",
    "\n",
    "os.chdir(current_dir)\n",
    "\n",
    "# IMPORTANT: Add src to Python path\n",
    "sys.path.insert(0, os.path.join(current_dir, \"src\"))\n",
    "\n",
    "print(\"Project root set to:\", current_dir)\n",
    "print(\"src added to path:\", os.path.join(current_dir, \"src\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/sukainaalkhalidy/Desktop/CMSE 495 capstone/NCEAS_Unsupervised_NLP/src', '/Users/sukainaalkhalidy/Desktop/CMSE 495 capstone/NCEAS_Unsupervised_NLP', '/opt/anaconda3/lib/python312.zip']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import phate\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import hdbscan\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.metrics import adjusted_rand_score, rand_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import phate\n",
    "import umap\n",
    "import hdbscan\n",
    "\n",
    "from custom_packages.diffusion_condensation import DiffusionCondensation as dc\n",
    "from custom_packages.fowlkes_mallows import FowlkesMallows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data (No Streaming Now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2951540it [00:23, 127738.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The evolution of the Earth-Moon system based o...</td>\n",
       "      <td>physics.gen-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Convergence of the discrete dipole approximati...</td>\n",
       "      <td>physics.optics physics.comp-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Convergence of the discrete dipole approximati...</td>\n",
       "      <td>physics.optics physics.comp-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The discrete dipole approximation for simulati...</td>\n",
       "      <td>physics.optics physics.comp-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The discrete dipole approximation: an overview...</td>\n",
       "      <td>physics.optics physics.comp-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924080</th>\n",
       "      <td>Variational methods, multiprecision and nonrel...</td>\n",
       "      <td>physics.atom-ph physics.comp-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924081</th>\n",
       "      <td>Effective interaction between helical bio-mole...</td>\n",
       "      <td>physics.bio-ph physics.chem-ph physics.comp-ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924082</th>\n",
       "      <td>Atom-optics hologram in the time domain   The ...</td>\n",
       "      <td>physics.atom-ph physics.optics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924083</th>\n",
       "      <td>A Second-Order Stochastic Leap-Frog Algorithm ...</td>\n",
       "      <td>physics.comp-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924084</th>\n",
       "      <td>Analytical Structure Matching and Very Precise...</td>\n",
       "      <td>physics.atom-ph</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>924085 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    topic  \\\n",
       "0       The evolution of the Earth-Moon system based o...   \n",
       "1       Convergence of the discrete dipole approximati...   \n",
       "2       Convergence of the discrete dipole approximati...   \n",
       "3       The discrete dipole approximation for simulati...   \n",
       "4       The discrete dipole approximation: an overview...   \n",
       "...                                                   ...   \n",
       "924080  Variational methods, multiprecision and nonrel...   \n",
       "924081  Effective interaction between helical bio-mole...   \n",
       "924082  Atom-optics hologram in the time domain   The ...   \n",
       "924083  A Second-Order Stochastic Leap-Frog Algorithm ...   \n",
       "924084  Analytical Structure Matching and Very Precise...   \n",
       "\n",
       "                                               categories  \n",
       "0                                          physics.gen-ph  \n",
       "1                          physics.optics physics.comp-ph  \n",
       "2                          physics.optics physics.comp-ph  \n",
       "3                          physics.optics physics.comp-ph  \n",
       "4                          physics.optics physics.comp-ph  \n",
       "...                                                   ...  \n",
       "924080                    physics.atom-ph physics.comp-ph  \n",
       "924081  physics.bio-ph physics.chem-ph physics.comp-ph...  \n",
       "924082                     physics.atom-ph physics.optics  \n",
       "924083                                    physics.comp-ph  \n",
       "924084                                    physics.atom-ph  \n",
       "\n",
       "[924085 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the big arXiv metadata file (it's huge, so we stream it)\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "file_path = \"/Users/sukainaalkhalidy/Desktop/CMSE 495 capstone/arxiv-metadata-oai-snapshot.json\"\n",
    "\n",
    "\n",
    "records = []  # We’ll store only the papers we actually care about\n",
    "\n",
    "# Read the file line by line so we don’t crash the computer\n",
    "with open(file_path, \"r\") as f:\n",
    "    for line in tqdm(f):  # Just to see progress because this takes a minute\n",
    "        paper = json.loads(line)\n",
    "        \n",
    "        # We only want Computer Science and Physics papers\n",
    "        # That matches our hierarchy goal and keeps things manageable\n",
    "        if paper[\"categories\"].startswith((\"cs.\", \"physics.\")):\n",
    "            \n",
    "            # Combine title + abstract into one text field for embeddings later\n",
    "            records.append({\n",
    "                \"topic\": paper[\"title\"] + \" \" + paper[\"abstract\"],\n",
    "                \"categories\": paper[\"categories\"]\n",
    "            })\n",
    "\n",
    "# Turn everything into a DataFrame so we can work with it easily\n",
    "df_arxiv = pd.DataFrame(records)\n",
    "\n",
    "# Quick check to make sure it loaded correctly\n",
    "df_arxiv.head()\n",
    "\n",
    "# Show full dataset\n",
    "df_arxiv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Semantic Agreement Enables Efficient Open-Ende...</td>\n",
       "      <td>cs.CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scheduling in Grid Computing Environment   Sch...</td>\n",
       "      <td>cs.DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taking off the Rose-Tinted Glasses: A Critical...</td>\n",
       "      <td>cs.LG cs.CR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Traffic Performance Score for Measuring the Im...</td>\n",
       "      <td>physics.soc-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SueNes: A Weakly Supervised Approach to Evalua...</td>\n",
       "      <td>cs.CL cs.IR cs.LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>Improving Neural Machine Translation by Multi-...</td>\n",
       "      <td>cs.CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>Strong Exciton-Vibrational Coupling in Molecul...</td>\n",
       "      <td>physics.chem-ph quant-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>Duality of generalized twisted Reed-Solomon co...</td>\n",
       "      <td>cs.IT math.IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>Non-consensus opinion models on complex networ...</td>\n",
       "      <td>physics.soc-ph cs.SI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>Energy-limited Joint Source--Channel Coding vi...</td>\n",
       "      <td>cs.IT eess.SP math.IT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   topic  \\\n",
       "0      Semantic Agreement Enables Efficient Open-Ende...   \n",
       "1      Scheduling in Grid Computing Environment   Sch...   \n",
       "2      Taking off the Rose-Tinted Glasses: A Critical...   \n",
       "3      Traffic Performance Score for Measuring the Im...   \n",
       "4      SueNes: A Weakly Supervised Approach to Evalua...   \n",
       "...                                                  ...   \n",
       "29995  Improving Neural Machine Translation by Multi-...   \n",
       "29996  Strong Exciton-Vibrational Coupling in Molecul...   \n",
       "29997  Duality of generalized twisted Reed-Solomon co...   \n",
       "29998  Non-consensus opinion models on complex networ...   \n",
       "29999  Energy-limited Joint Source--Channel Coding vi...   \n",
       "\n",
       "                     categories  \n",
       "0                         cs.CL  \n",
       "1                         cs.DC  \n",
       "2                   cs.LG cs.CR  \n",
       "3                physics.soc-ph  \n",
       "4             cs.CL cs.IR cs.LG  \n",
       "...                         ...  \n",
       "29995                     cs.CL  \n",
       "29996  physics.chem-ph quant-ph  \n",
       "29997             cs.IT math.IT  \n",
       "29998      physics.soc-ph cs.SI  \n",
       "29999     cs.IT eess.SP math.IT  \n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The full dataset is way too big to embed, so we randomly sample 30,000 papers.\n",
    "# random_state=42 keeps it reproducible (so we always get the same sample).\n",
    "# reset_index just cleans up the index after sampling.\n",
    "df_arxiv = df_arxiv.sample(30000, random_state=42).reset_index(drop=True)\n",
    "df_arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>category_0</th>\n",
       "      <th>category_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Semantic Agreement Enables Efficient Open-Ende...</td>\n",
       "      <td>cs</td>\n",
       "      <td>cs.CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scheduling in Grid Computing Environment   Sch...</td>\n",
       "      <td>cs</td>\n",
       "      <td>cs.DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taking off the Rose-Tinted Glasses: A Critical...</td>\n",
       "      <td>cs</td>\n",
       "      <td>cs.LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Traffic Performance Score for Measuring the Im...</td>\n",
       "      <td>physics</td>\n",
       "      <td>physics.soc-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SueNes: A Weakly Supervised Approach to Evalua...</td>\n",
       "      <td>cs</td>\n",
       "      <td>cs.CL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               topic category_0  \\\n",
       "0  Semantic Agreement Enables Efficient Open-Ende...         cs   \n",
       "1  Scheduling in Grid Computing Environment   Sch...         cs   \n",
       "2  Taking off the Rose-Tinted Glasses: A Critical...         cs   \n",
       "3  Traffic Performance Score for Measuring the Im...    physics   \n",
       "4  SueNes: A Weakly Supervised Approach to Evalua...         cs   \n",
       "\n",
       "       category_1  \n",
       "0           cs.CL  \n",
       "1           cs.DC  \n",
       "2           cs.LG  \n",
       "3  physics.soc-ph  \n",
       "4           cs.CL  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_categories(cat_string):\n",
    "    primary = cat_string.split()[0]\n",
    "    top_level = primary.split('.')[0]\n",
    "    return top_level, primary\n",
    "\n",
    "df_arxiv[[\"category_0\", \"category_1\"]] = df_arxiv[\"categories\"].apply(\n",
    "    lambda x: pd.Series(extract_categories(x))\n",
    ")\n",
    "\n",
    "df_arxiv = df_arxiv[[\"topic\", \"category_0\", \"category_1\"]]\n",
    "df_arxiv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build topic_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dict = {}\n",
    "\n",
    "for col in df_arxiv.columns:\n",
    "    if re.match(r'^category_\\d+$', col):\n",
    "        unique_count = len(df_arxiv[col].unique())\n",
    "        topic_dict[unique_count] = np.array(df_arxiv[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define cluster levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster levels: [62, 2]\n"
     ]
    }
   ],
   "source": [
    "depth = 2\n",
    "cluster_levels = []\n",
    "\n",
    "for i in reversed(range(depth)):\n",
    "    cluster_levels.append(len(df_arxiv[f'category_{i}'].unique()))\n",
    "\n",
    "print(\"Cluster levels:\", cluster_levels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Qwen Embeddings\n",
    "# You Are Now Ready For:\n",
    "Step 4 — Load Qwen embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'gpt_embeddings/arxiv_qwen_embeddings.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m embeddings = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt_embeddings/arxiv_qwen_embeddings.npy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEmbeddings shape:\u001b[39m\u001b[33m\"\u001b[39m, embeddings.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:451\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    449\u001b[39m     own_fid = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     fid = stack.enter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    452\u001b[39m     own_fid = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    454\u001b[39m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'gpt_embeddings/arxiv_qwen_embeddings.npy'"
     ]
    }
   ],
   "source": [
    "embeddings = np.load(\"gpt_embeddings/arxiv_qwen_embeddings.npy\")\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create embedding_methods (THIS WAS MISSING)\n",
    "# Build embedding_methods\n",
    "Then:\n",
    "PHATE\n",
    "PCA\n",
    "UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# PHATE\u001b[39;00m\n\u001b[32m      4\u001b[39m phate_model = phate.PHATE(n_components=\u001b[32m300\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m embedding_methods[\u001b[33m\"\u001b[39m\u001b[33mPHATE\u001b[39m\u001b[33m\"\u001b[39m] = phate_model.fit_transform(\u001b[43membeddings\u001b[49m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# PCA\u001b[39;00m\n\u001b[32m      8\u001b[39m pca = PCA(n_components=\u001b[32m300\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_methods = {}\n",
    "\n",
    "# PHATE\n",
    "phate_model = phate.PHATE(n_components=300, random_state=42)\n",
    "embedding_methods[\"PHATE\"] = phate_model.fit_transform(embeddings)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=300)\n",
    "embedding_methods[\"PCA\"] = pca.fit_transform(embeddings)\n",
    "\n",
    "# UMAP\n",
    "umap_model = umap.UMAP(n_components=300, random_state=42)\n",
    "embedding_methods[\"UMAP\"] = umap_model.fit_transform(embeddings)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
